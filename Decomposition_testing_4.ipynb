{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5bfa8726-e3e8-4d3d-ae62-d5c7afb5182f",
      "metadata": {
        "id": "5bfa8726-e3e8-4d3d-ae62-d5c7afb5182f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "kmZIbeVRWJtf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmZIbeVRWJtf",
        "outputId": "f9b44cc4-3434-47e2-ad43-334b42e5ec51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorly in c:\\users\\administrator\\desktop\\skoltech\\ml\\project\\mlbyteclub\\.venv\\lib\\site-packages (0.8.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\administrator\\desktop\\skoltech\\ml\\project\\mlbyteclub\\.venv\\lib\\site-packages (from tensorly) (1.26.4)\n",
            "Requirement already satisfied: scipy in c:\\users\\administrator\\desktop\\skoltech\\ml\\project\\mlbyteclub\\.venv\\lib\\site-packages (from tensorly) (1.12.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3295a35",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "5ec53012-b9d7-4dde-b4f3-9efd3579b22e",
      "metadata": {
        "id": "5ec53012-b9d7-4dde-b4f3-9efd3579b22e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def quantization_forw(T,z,b,scale):\n",
        "  T = np.clip(np.round(T/scale)+z,-2**(b-1),2**(b-1)-1)\n",
        "  return T.int()\n",
        "\n",
        "def quantization_back(T,z,scale):\n",
        "  return scale * (T - z)\n",
        "\n",
        "def ADMM(B, U, K, G, rank, scale):\n",
        "    ro = torch.trace(G) / rank\n",
        "\n",
        "    LL = G + ro * torch.eye(*G.size())\n",
        "    L = torch.linalg.cholesky(LL)\n",
        "    LL_inv = torch.cholesky_inverse(L)\n",
        "\n",
        "    r = torch.inf\n",
        "    s = torch.inf\n",
        "\n",
        "    for _ in range(100):\n",
        "    # while (r > 0.01) or (s > 0.01):\n",
        "        # print(r, s)\n",
        "        B_ = LL_inv @ (K + ro * (B + U)).T\n",
        "        B0 = torch.clone(B)\n",
        "\n",
        "        B = quantization_back(quantization_forw(B_.T - U, 0, 8, scale), 0, scale)\n",
        "        U = U + B - B_.T\n",
        "\n",
        "        r = torch.norm(B - B_.T, p='fro')**2 / torch.norm(B, p='fro')**2\n",
        "        s = torch.norm(B - B0, p='fro')**2 / torch.norm(U, p='fro')**2\n",
        "    return B, U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "332257f5-30b9-477c-8ff1-16a2239cc839",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "332257f5-30b9-477c-8ff1-16a2239cc839",
        "outputId": "fd05d5fb-c2e9-4f42-9c04-be972915310e",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 6.8027,  7.8547,  8.5403,  8.2032,  4.5853, 10.4625,  4.7139,  6.6861],\n",
            "        [ 1.6585,  5.4313,  2.8276,  6.6951,  2.5012,  5.7220,  4.2487,  5.6129],\n",
            "        [ 1.3603,  5.4062,  2.5209,  6.7618,  2.4258,  5.5513,  4.3235,  5.6815],\n",
            "        [ 4.1776,  7.1743,  5.7430,  8.1764,  3.7407,  8.5451,  4.9669,  6.7686],\n",
            "        [ 5.1084,  3.9433,  5.9987,  3.5495,  2.6741,  6.0934,  1.8166,  2.8063],\n",
            "        [ 8.4806,  3.6342,  9.3413,  2.0041,  3.2936,  7.4893,  0.4487,  1.3601]],\n",
            "       dtype=torch.float64)\n",
            "tensor(0.3400, dtype=torch.float64)\n",
            "tensor(0.0234, dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "from tensorly.decomposition import parafac\n",
        "\n",
        "def e_quant(X,A,B):\n",
        "  return torch.norm(X - A@B.T, p='fro')/torch.norm(X, p='fro')\n",
        "\n",
        "M = 6\n",
        "N = 8\n",
        "\n",
        "X = np.random.rand(M, N)*10\n",
        "reduction_rate = 2\n",
        "rank = round(M*N/(M + N)/reduction_rate)\n",
        "\n",
        "weights, factors = parafac(X, rank=rank)\n",
        "A = torch.from_numpy(factors[0])\n",
        "B = torch.from_numpy(factors[1])\n",
        "\n",
        "print(A@B.T)\n",
        "\n",
        "X = torch.from_numpy(X)\n",
        "\n",
        "U_A = torch.zeros_like(A)\n",
        "U_B = torch.zeros_like(B)\n",
        "\n",
        "e_old = 0.\n",
        "e_new = e_quant(X,A,B)\n",
        "\n",
        "b=8\n",
        "#scale = (torch.max(X)-torch.min(X))/(2**b-1)\n",
        "q_max = 9.89675982 * torch.mean(torch.abs(X - X.mean()))\n",
        "scale = 2*q_max/(2**b-1)\n",
        "\n",
        "while torch.abs(e_new - e_old) > 0.01:\n",
        "    print(torch.abs(e_new - e_old))\n",
        "    K = X.T @ A\n",
        "    G = A.T @ A\n",
        "    B, U_B = ADMM(B, U_B, K, G, rank, scale)\n",
        "\n",
        "    K = X @ B\n",
        "    G = B.T @ B\n",
        "    A, U_A = ADMM(A, U_A, K, G, rank, scale)\n",
        "\n",
        "    e_old = e_new\n",
        "    e_new = e_quant(X,A,B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "EvMP9ksBf01F",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvMP9ksBf01F",
        "outputId": "619dd120-7fb6-48cc-f898-8b10bea98d5a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 5.4471,  8.3955,  9.8947,  7.8958,  4.4476,  8.8952,  3.9479,  7.8958],\n",
              "        [ 1.1994,  5.6470,  3.6980,  6.2966,  2.4987,  4.9973,  3.1483,  6.2966],\n",
              "        [ 0.5997,  5.6969,  2.9984,  6.5965,  2.3987,  4.7974,  3.2982,  6.5965],\n",
              "        [ 3.4981,  7.4960,  7.1961,  7.5959,  3.6980,  7.3960,  3.7980,  7.5959],\n",
              "        [ 4.4976,  4.2477,  7.0962,  3.2982,  2.5986,  5.1972,  1.6491,  3.2982],\n",
              "        [ 7.5460,  3.8479, 10.5943,  1.5991,  3.0484,  6.0967,  0.7996,  1.5991]],\n",
              "       dtype=torch.float64)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A@B.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "OaJlO0fEDotb",
      "metadata": {
        "id": "OaJlO0fEDotb"
      },
      "outputs": [],
      "source": [
        "from tensorly.decomposition import parafac\n",
        "\n",
        "def e_quant(X,A,B):\n",
        "  return torch.norm(X - A@B.T, p='fro')/torch.norm(X, p='fro')\n",
        "\n",
        "def factorize(W, reduction_rate = 2):\n",
        "    M,N = W.shape\n",
        "    rank = round(M*N/(M + N)/reduction_rate)\n",
        "\n",
        "    #W - должен быть просто numpy массивом\n",
        "    weights, factors = parafac(W, rank=rank)\n",
        "    A = torch.from_numpy(factors[0])\n",
        "    B = torch.from_numpy(factors[1])\n",
        "    new_W = A@B.T\n",
        "\n",
        "    W = torch.from_numpy(W)\n",
        "\n",
        "    U_A = torch.zeros_like(A)\n",
        "    U_B = torch.zeros_like(B)\n",
        "\n",
        "    e_old = 0.\n",
        "    e_new = e_quant(W,A,B)\n",
        "\n",
        "    b=8\n",
        "    #scale1 = (torch.max(A)-torch.min(A))/(2**b-1)\n",
        "    #scale2 = (torch.max(B)-torch.min(B))/(2**b-1)\n",
        "    #q_max = 9.89675982 * torch.mean(torch.abs(A - A.mean()))\n",
        "    #scale2 = 2*q_max/(2**b-1)\n",
        "    #q_max = 9.89675982 * torch.mean(torch.abs(B - B.mean()))\n",
        "    #scale1 = 2*q_max/(2**b-1)\n",
        "    q_max = 9.89675982 * torch.mean(torch.abs(W - W.mean()))\n",
        "    # scale = 2*q_max/(2**b-1)\n",
        "\n",
        "    scale = (torch.max(torch.abs(W))/(2**(8-1)-1))\n",
        "\n",
        "    while torch.abs(e_new - e_old) > 0.01:\n",
        "        print(f'error: {torch.abs(e_new - e_old)}')\n",
        "        K = W @ B\n",
        "        G = B.T @ B\n",
        "        A, U_A = ADMM(A, U_A, K, G, rank, scale)  \n",
        "        \n",
        "        K = W.T @ A\n",
        "        G = A.T @ A\n",
        "        B, U_B = ADMM(B, U_B, K, G, rank, scale)\n",
        "\n",
        "        e_old = e_new\n",
        "        e_new = e_quant(X,A,B)\n",
        "    \n",
        "    print(f'error: {torch.abs(e_new - e_old)}')\n",
        "\n",
        "    return new_W, A, B, scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "QhkWa4RkHe44",
      "metadata": {
        "id": "QhkWa4RkHe44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "error: 0.3163478172648995\n",
            "error: 0.024230089950282474\n",
            "error: 0.011770858379707316\n",
            "error: 0.005675450387603698\n"
          ]
        }
      ],
      "source": [
        "#W - матрица весов в .numpy\n",
        "X = np.random.rand(6, 8)*10\n",
        "X = torch.from_numpy(X)\n",
        "newX, A, B, scale = factorize(X.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "iQpVe9TZFLl1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQpVe9TZFLl1",
        "outputId": "2f4cbd2d-4347-4d30-aa99-3172377b8047"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[6.72747202, 6.10906426, 8.52791918, 9.92261306, 9.94754311,\n",
              "         2.30469858, 5.25550473, 2.69578374],\n",
              "        [3.5871028 , 9.23017548, 9.21799721, 6.45569961, 2.54199481,\n",
              "         3.0045621 , 1.21453183, 2.19483124],\n",
              "        [7.90550384, 3.48360502, 2.27560604, 3.69690455, 8.29237368,\n",
              "         2.67094683, 1.08367524, 7.09211689],\n",
              "        [1.97623797, 6.11291657, 9.38756413, 5.00168264, 3.92483548,\n",
              "         7.87870521, 4.7067804 , 5.1387224 ],\n",
              "        [8.83665428, 4.68968889, 3.24781985, 9.05458534, 2.14555517,\n",
              "         9.85939397, 3.72208043, 7.86031403],\n",
              "        [4.37589395, 0.09990548, 9.71908443, 9.55140093, 6.84323541,\n",
              "         0.47116207, 4.87860879, 3.18443112]]),\n",
              " tensor([[ 5.5807,  5.6169, 10.6924,  9.6252,  8.1083,  2.8784,  4.8354,  3.7958],\n",
              "         [ 4.4905,  4.2645,  7.2391,  6.9226,  5.5884,  2.8983,  3.4286,  3.3578],\n",
              "         [ 5.3683,  4.2791,  4.2739,  5.6362,  3.6764,  5.3339,  2.6154,  4.9885],\n",
              "         [ 5.7599,  4.9470,  6.4884,  7.1940,  5.2497,  4.9112,  3.4506,  4.9292],\n",
              "         [ 8.4417,  6.1382,  3.5619,  6.9593,  3.6145,  9.7354,  3.0429,  8.5471],\n",
              "         [ 3.7015,  4.2231,  9.7532,  7.9878,  7.2034,  0.7736,  4.1084,  1.9257]],\n",
              "        dtype=torch.float64),\n",
              " tensor([[ 4.8836,  5.1167,  9.8162,  8.4665,  7.5830,  2.7547,  4.2332,  3.7670],\n",
              "         [ 4.7609,  4.5339,  7.5708,  6.9818,  5.9388,  3.5032,  3.4909,  3.9449],\n",
              "         [ 5.4971,  4.2885,  4.5768,  5.4112,  3.8283,  5.7486,  2.7056,  5.1228],\n",
              "         [ 6.0615,  5.1044,  6.6996,  7.0186,  5.4235,  5.6627,  3.5093,  5.4235],\n",
              "         [ 8.8101,  6.0983,  3.9265,  6.5032,  3.6565, 10.6077,  3.2516,  8.6751],\n",
              "         [ 3.7792,  4.4725,  9.8530,  7.9879,  7.5094,  1.2086,  3.9940,  2.6074]],\n",
              "        dtype=torch.float64),\n",
              " tensor(0.0783, dtype=torch.float64))"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.numpy(), newX, A@B.T, scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "jrl48MM0HBuO",
      "metadata": {
        "id": "jrl48MM0HBuO"
      },
      "outputs": [],
      "source": [
        "A_int = (A/scale).int()\n",
        "B_int = (B/scale).int()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "916597c7",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 4.8836,  5.1167,  9.8162,  8.4665,  7.5830,  2.7547,  4.2332,  3.7670],\n",
              "        [ 4.7609,  4.5339,  7.5708,  6.9818,  5.9388,  3.5032,  3.4909,  3.9449],\n",
              "        [ 5.4971,  4.2885,  4.5768,  5.4112,  3.8283,  5.7486,  2.7056,  5.1228],\n",
              "        [ 6.0615,  5.1044,  6.6996,  7.0186,  5.4235,  5.6627,  3.5093,  5.4235],\n",
              "        [ 8.8101,  6.0983,  3.9265,  6.5032,  3.6565, 10.6077,  3.2516,  8.6751],\n",
              "        [ 3.7792,  4.4725,  9.8530,  7.9879,  7.5094,  1.2086,  3.9940,  2.6074]],\n",
              "       dtype=torch.float64)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A_int@B_int.T * scale**2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "ndHkxhbhHn_B",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndHkxhbhHn_B",
        "outputId": "efcf3629-fd24-408d-adf0-a18f57ee763e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 92.9666, 106.2344, 126.0132, 114.5786,  92.6082,  82.0208,  52.0683,\n",
              "         84.1941], dtype=torch.float64)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#придумай свой входной вектор\n",
        "Z = torch.from_numpy(np.array([2.,5.,4.,4.,2.,1.]))\n",
        "Z@X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "c219e8b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "scale_Z = (torch.max(torch.abs(Z))/(2**(8-1)-1))\n",
        "Z_int = quantization_forw(Z, 0, 8, scale_Z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "57R_h3PgH7kR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57R_h3PgH7kR",
        "outputId": "7b677c45-5d16-4e18-c575-1f980ea53e04"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([101.4355,  87.3093, 120.4284, 122.7433,  96.8057,  91.3604,  61.3717,\n",
              "         89.6242], dtype=torch.float64)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(Z_int @ A_int @ B_int.T) * scale_Z * scale**2"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
