{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c00da410-6756-499f-a4ea-8801dab5053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e43a79a3-ab45-4dea-ace3-c189893ce841",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/Plane_dataset/train.csv', index_col=0)\n",
    "df_train['Arrival Delay in Minutes'] = df_train['Arrival Delay in Minutes'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e1831c6-3c6c-4748-8aea-cb66f51eacad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./data/Plane_dataset/test.csv', index_col=0)\n",
    "df_test = df_test.drop(columns=['id']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7f4d656-884a-4e7b-89be-4ec4f8afcd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val = df_train.iloc[:, :-1].copy()\n",
    "y_train_val = df_train.iloc[:, -1].copy()\n",
    "\n",
    "X_train_val = X_train_val.drop(columns=['id'])\n",
    "\n",
    "y_train_val = pd.get_dummies(y_train_val, drop_first=True)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1, random_state=102)\n",
    "\n",
    "X_test = df_test.iloc[:, :-1].copy()\n",
    "y_test = df_test.iloc[:, -1].copy()\n",
    "\n",
    "y_test = pd.get_dummies(y_test, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "661a74b0-bd05-4f00-a6ea-e4a89836e260",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['Age', 'Flight Distance', 'Departure Delay in Minutes', 'Arrival Delay in Minutes']\n",
    "cat_cols = X_train_val.drop(columns=num_cols).columns.tolist()\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "one_hot = OneHotEncoder(drop='if_binary', sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "        ('one_hot', one_hot, cat_cols),\n",
    "        ('scaler', X_scaler, num_cols)\n",
    "])\n",
    "\n",
    "X_train_transformed = ct.fit_transform(X_train)\n",
    "X_val_transformed = ct.transform(X_val)\n",
    "X_test_transformed = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ba0b11f-0d6f-4cf3-a259-4c146b6078ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = torch.from_numpy(X_train_transformed).float()\n",
    "X_val_transformed = torch.from_numpy(X_val_transformed).float()\n",
    "X_test_transformed = torch.from_numpy(X_test_transformed).float()\n",
    "\n",
    "y_train = torch.from_numpy(y_train.values).squeeze().long()\n",
    "y_val = torch.from_numpy(y_val.values).squeeze().long()\n",
    "y_test = torch.from_numpy(y_test.values).squeeze().long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afe8836-32c1-43ec-90f8-cab8bb9777bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f491a5d-a290-4cf4-b0c0-15e497407a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfa89448-74db-46eb-81e4-6da9924d4d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "\n",
    "train_dataset = TensorDataset(X_train_transformed, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(X_val_transformed, y_val)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "test_dataset = TensorDataset(X_test_transformed, y_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ec14e87-aa98-4744-b09e-6a3f1aa516ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model import MLP, train, test, print_size_of_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ed389de-1648-49c7-96b6-392862ccc99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MLP(input_size=93, output_size=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f3f7b08-82fe-485e-aa04-eca4b96831bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "MODEL_FILENAME = './Saved_models/Plane.pt'\n",
    "\n",
    "if Path(MODEL_FILENAME).exists():\n",
    "    net.load_state_dict(torch.load(MODEL_FILENAME))\n",
    "    print('Loaded model from disk')\n",
    "else:\n",
    "    train(net, train_loader, val_loader, 1000, 5, device=device)\n",
    "    torch.save(net.state_dict(), MODEL_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "816e8c35-ece0-4b30-a909-611d7a7c8772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf09367116846b096267f96e5c35e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2590 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model before quantization: 96.35\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy of the model before quantization: {test(net, test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868617ef-28b9-4379-b4a3-7ac32ee00035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50c8f629-f06d-45d6-b7c3-997004777ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Factorization import factorize, SVD_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "745fdf6b-c3ef-43bc-9cc5-b21e3ab7e39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction_rate = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "097461b2-4954-4522-a2ff-32ae38eaff13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight\n",
      "linear2.weight\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "net_state_copy = net.state_dict().copy()\n",
    "linear_weights_keys = [layer for layer in net_state_copy if 'linear' in layer and '.weight' in layer]\n",
    "\n",
    "for layer in linear_weights_keys[:-1]:\n",
    "    print(layer)\n",
    "    W = net.state_dict()[layer].detach()\n",
    "    # net_state_copy[layer] = factorize(W, torch.linalg.matrix_rank(W) // reduction_rate, method='min-max')\n",
    "    net_state_copy[layer] = SVD_quant(W, torch.linalg.matrix_rank(W) // reduction_rate, method='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "701782e7-f410-4542-919b-c21935c06483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf409b654514208a66e6586f706e622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2590 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "95.45"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_net = MLP(input_size=93, output_size=2).to(device)\n",
    "new_net.load_state_dict(net_state_copy)\n",
    "\n",
    "test(new_net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0710a496-e1db-4372-968d-301a7699cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank: 31\n",
      "rank: 33\n",
      "Initial (byte): 77200\n",
      "Compressed (byte): 12583\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "net_state_copy = net.state_dict().copy()\n",
    "linear_weights_keys = [layer for layer in net_state_copy if 'linear' in layer and '.weight' in layer]\n",
    "\n",
    "mem_usage_init = []\n",
    "mem_usage_compressed = []\n",
    "\n",
    "for layer in linear_weights_keys[:-1]:\n",
    "    W = net.state_dict()[layer].detach()\n",
    "    A, B, sc = factorize(W, torch.linalg.matrix_rank(W) // reduction_rate, return_int=True)\n",
    "\n",
    "    mem_usage_init.append(W.element_size() * W.numel())\n",
    "    mem_usage_compressed.append(A.element_size() * A.numel() + B.element_size() * B.numel())\n",
    "\n",
    "print(f'Initial (byte): {sum(mem_usage_init)}')\n",
    "print(f'Compressed (byte): {sum(mem_usage_compressed)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
