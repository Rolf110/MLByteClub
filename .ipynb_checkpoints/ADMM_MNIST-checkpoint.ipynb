{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.datasets as datasets \n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make torch deterministic\n",
    "_ = torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "mnist_train_valset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "dataset_size = len(mnist_train_valset)\n",
    "\n",
    "train_size = int(0.9 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(mnist_train_valset, [train_size, val_size])\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(mnist_testset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model import MLP, train, test, print_size_of_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MLP(input_size=28*28, output_size=10).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "MODEL_FILENAME = './Saved_models/Mnist.pt'\n",
    "\n",
    "if Path(MODEL_FILENAME).exists():\n",
    "    net.load_state_dict(torch.load(MODEL_FILENAME))\n",
    "    print('Loaded model from disk')\n",
    "else:\n",
    "    train(net, train_loader, val_loader, 1000, 5, device=device)\n",
    "    torch.save(net.state_dict(), MODEL_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print weights and size of the model before quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b73ff0153ae14719908a845182f11c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model before quantization: 97.37\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy of the model before quantization: {test(net, test_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Factorization import factorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполните эту ячейку, если будете что-то менять в Factorize.py, так ipynb импортирует новые изменения\n",
    "# Если этого не сделать, то придется перезагружать ядро, что не очень удобно\n",
    "\n",
    "import importlib\n",
    "import Factorization\n",
    "\n",
    "importlib.reload(Factorization)\n",
    "from Factorization import factorize, SVD_quant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction_rate = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear2.weight\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "net_state_copy = net.state_dict().copy()\n",
    "linear_weights_keys = [layer for layer in net_state_copy if 'linear' in layer and '.weight' in layer]\n",
    "\n",
    "for layer in linear_weights_keys[1:-1]:\n",
    "    print(layer)\n",
    "    W = net.state_dict()[layer].detach()\n",
    "    # net_state_copy[layer] = factorize(W, torch.linalg.matrix_rank(W) // reduction_rate, method='min-max')\n",
    "    net_state_copy[layer] = SVD_quant(W, torch.linalg.matrix_rank(W) // reduction_rate, method='min-max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f83341a1bd24c8487774f75b80955be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "83.91"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_net = MLP(input_size=28*28, output_size=10).to(device)\n",
    "new_net.load_state_dict(net_state_copy)\n",
    "\n",
    "test(new_net, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank: 33\n",
      "Initial (byte): 40000\n",
      "Compressed (byte): 6600\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "net_state_copy = net.state_dict().copy()\n",
    "linear_weights_keys = [layer for layer in net_state_copy if 'linear' in layer and '.weight' in layer]\n",
    "\n",
    "mem_usage_init = []\n",
    "mem_usage_compressed = []\n",
    "\n",
    "for layer in linear_weights_keys[1:-1]:\n",
    "    W = net.state_dict()[layer].detach()\n",
    "    A, B, sc = factorize(W, torch.linalg.matrix_rank(W) // reduction_rate, return_int=True)\n",
    "\n",
    "    mem_usage_init.append(W.element_size() * W.numel())\n",
    "    mem_usage_compressed.append(A.element_size() * A.numel() + B.element_size() * B.numel())\n",
    "\n",
    "print(f'Initial (byte): {sum(mem_usage_init)}')\n",
    "print(f'Compressed (byte): {sum(mem_usage_compressed)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
